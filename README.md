# ğŸš€ Transformer Neural Machine Translation (ENâ†’DE)
ğŸ§  Transformer æ¨¡å‹å®ç°ä¸è®­ç»ƒè¯´æ˜
ğŸ“‹ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ª åŸºäº Transformer Encoderâ€“Decoder æ¶æ„ çš„ç¥ç»æœºå™¨ç¿»è¯‘æ¨¡å‹ï¼ˆEnglish â†’ Germanï¼‰ï¼Œæ”¯æŒ ç›¸å¯¹ä½ç½®ç¼–ç ï¼ˆRelative Positional Encodingï¼‰ã€‚
ä¸»è¦å†…å®¹åŒ…æ‹¬ï¼š

æ‰‹å·¥å®ç°å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ˆMulti-Head Self-Attentionï¼‰

å‰é¦ˆç½‘ç»œï¼ˆPosition-wise FeedForwardï¼‰

æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–ï¼ˆResidual + LayerNormï¼‰

ç›¸å¯¹ä¸ç»å¯¹ä½ç½®ç¼–ç æœºåˆ¶

BLEU åˆ†æ•°è®¡ç®—ä¸å¯è§†åŒ–åˆ†æ

âš™ï¸ ç¡¬ä»¶ä¸ç¯å¢ƒè¦æ±‚
ğŸ–¥ï¸ ç¡¬ä»¶é…ç½®
é¡¹ç›®	æ¨èé…ç½®
GPU	NVIDIA GeForce RTX 4090 (24GB VRAM)
CPU	Intel i9 / AMD Ryzen 9 
å†…å­˜	â‰¥ 32 GB
ç¡¬ç›˜	â‰¥ 100 GB å¯ç”¨ç©ºé—´
CUDA ç‰ˆæœ¬	11.8

è‹¥ä½¿ç”¨å…¶ä»– GPUï¼ˆå¦‚ 3090ã€A100ï¼‰ï¼Œåªéœ€ä¿æŒç›¸åŒçš„ CUDA ç‰ˆæœ¬å’Œ PyTorch å…¼å®¹æ€§å³å¯ã€‚

ğŸ§© è½¯ä»¶ç¯å¢ƒ
ğŸ“¦ å®‰è£…ä¾èµ–

å»ºè®®ä½¿ç”¨ Python 3.10+ ä¸ è™šæ‹Ÿç¯å¢ƒï¼ˆconda æˆ– venvï¼‰ï¼š

# åˆ›å»ºå¹¶æ¿€æ´»ç¯å¢ƒ
conda create -n transformer python=3.10
conda activate transformer

# å®‰è£…ä¾èµ–
pip install -r requirements.txt


requirements.txt å†…å®¹å¦‚ä¸‹ï¼š

torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0
sentencepiece>=0.1.99
nltk>=3.8.1
matplotlib>=3.7.0
tqdm>=4.65.0
loguru>=0.7.0
numpy>=1.23.0
pandas>=2.0.0

ğŸ“‚ é¡¹ç›®ç»“æ„

Transformer_Assignment/

â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py              # Transformer æ¨¡å‹å®šä¹‰ï¼ˆEncoderã€Decoderã€Attentionç­‰ï¼‰
â”‚   â”œâ”€â”€ train.py              # è®­ç»ƒä¸éªŒè¯ä¸»è„šæœ¬            
â”‚
â”œâ”€â”€ data/
â”‚
â”œâ”€â”€ result/                   # æ¨¡å‹æƒé‡ã€æ›²çº¿ä¸æ—¥å¿—è¾“å‡ºæ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ loss_curve.png
â”‚   â”œâ”€â”€ bleu_curve.png
â”‚   â”œâ”€â”€ learning_rate.png
â”‚   â”œâ”€â”€ epoch_time.png
â”‚   â”œâ”€â”€ performance_summary.png
â”‚   â””â”€â”€ best_model.pt
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


ğŸš€ è¿è¡Œä¸å¤ç°å®éªŒ
ğŸ¯ å•æ¬¡è®­ç»ƒå‘½ä»¤

ä»¥ä¸‹å‘½ä»¤å¯åœ¨ RTX 4090 ä¸Šç›´æ¥å¤ç°å®éªŒç»“æœï¼š

python src/train.py \
  --epochs 20 \
  --lr 5e-4 \
  --batch-size 64 \
  --save-dir result \
  --warmup-steps 4000 \
  --max-steps 50000 \
  --max-train-samples 200000 \
  --relative-position \
  --seed 42


å»ºè®®ä½¿ç”¨ --seed 42 ä»¥ä¿è¯å¯å¤ç°æ€§ã€‚
æ‰€æœ‰è®­ç»ƒæ—¥å¿—å’Œæ¨¡å‹æ–‡ä»¶å°†è‡ªåŠ¨ä¿å­˜åœ¨ result/ æ–‡ä»¶å¤¹ä¸­ã€‚

ğŸ“Š è¾“å‡ºä¸ç»“æœ

è®­ç»ƒç»“æŸåï¼Œç¨‹åºä¼šè‡ªåŠ¨ç”Ÿæˆä»¥ä¸‹å¯è§†åŒ–ç»“æœï¼š

å›¾è¡¨	æ–‡ä»¶	è¯´æ˜
è®­ç»ƒ & éªŒè¯ Loss æ›²çº¿	result/loss_curve.png	æ¨¡å‹æ”¶æ•›æƒ…å†µ
BLEU åˆ†æ•°æ›²çº¿	result/bleu_curve.png	ç¿»è¯‘è´¨é‡å˜åŒ–
å­¦ä¹ ç‡å˜åŒ–æ›²çº¿	result/learning_rate.png	Noam Scheduler å¯è§†åŒ–
æ¯è½®è®­ç»ƒè€—æ—¶	result/epoch_time.png	æ€§èƒ½åˆ†æ
ç»¼åˆæ€§èƒ½å¯¹æ¯”å›¾	result/performance_summary.png	å®éªŒæ€»ç»“
ğŸ“ˆ BLEU è¯„ä¼°

æ¨¡å‹è®­ç»ƒå®Œæˆåä¼šåœ¨éªŒè¯é›†ä¸æµ‹è¯•é›†ä¸Šè‡ªåŠ¨è®¡ç®— BLEU åˆ†æ•°ï¼š

bleu = calculate_bleu(model, valid_loader, sp, device)


è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š

Epoch [10/20] | Train Loss: 4.85 | Valid Loss: 4.67 | BLEU: 27.4

ğŸ§ª å¯é€‰å®éªŒè®¾ç½®
å®éªŒå˜é‡	å‚æ•°å	ç¤ºä¾‹
å…³é—­ç›¸å¯¹ä½ç½®ç¼–ç 	ç§»é™¤ --relative-position	baseline
ä¿®æ”¹å­¦ä¹ ç‡	--lr	--lr 3e-4
è°ƒæ•´warmupæ­¥æ•°	--warmup-steps	--warmup-steps 8000
æ§åˆ¶æœ€å¤§æ ·æœ¬é‡	--max-train-samples	--max-train-samples 100000
æ”¹å˜batch size	--batch-size	--batch-size 128
